

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/AcceptedHelper/img/favicon.ico">
  <link rel="icon" href="/AcceptedHelper/img/favicon.ico">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="FDU19CS">
  <meta name="keywords" content="">
  
  <title>数据挖掘笔记 - AcceptedHelper</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/AcceptedHelper/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.4.0/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/AcceptedHelper/css/main.css" />

<!-- 自定义样式保持在最底部 -->

  
<link rel="stylesheet" href="/AcceptedHelper/css/custom.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"fdu19cs.github.io","root":"/AcceptedHelper/","version":"1.8.9a","typing":{"enable":false,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}}};
  </script>
  <script  src="/AcceptedHelper/js/utils.js" ></script>
  <script  src="/AcceptedHelper/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/AcceptedHelper/">&nbsp;<strong>AcceptedHelper</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/AcceptedHelper/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/AcceptedHelper/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/AcceptedHelper/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/AcceptedHelper/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/AcceptedHelper/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/AcceptedHelper/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="数据挖掘笔记">
              
                数据挖掘笔记
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2021-12-03 15:36" pubdate>
        2021年12月3日 下午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      8.9k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      121
       分钟
    </span>
  

  
  
    
      <!-- 不蒜子统计文章PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">数据挖掘笔记</h1>
            
            <div class="markdown-body">
              <h1 id="数据挖掘笔记"><a href="#数据挖掘笔记" class="headerlink" title="数据挖掘笔记"></a>数据挖掘笔记</h1><h2 id="习题课"><a href="#习题课" class="headerlink" title="习题课"></a>习题课</h2><ol>
<li>盒图：五数概括不用判定离群点，盒图要判定离群点</li>
<li>中位数概括宽度不用+1</li>
<li>OLAP基础操作 专有名词</li>
<li>15选择（1分）+5填空（2分）+4大题</li>
<li>upd：<strong>20-21春学期期末</strong><ul>
<li>大题考了用基尼系数做朴素贝叶斯概率、频繁模式挖掘、k近邻聚类、神经网络参数计算（求导大法）。确实都是作业出现过的题型，但是数不好算，聚类和基尼系数要按的计算器太多了。老师最后开始频繁催“算不出来数没关系，写对公式就给绝大部分分；写不出来公式写算法，至少写点东西好给分”。</li>
<li>前几章的计算只考了小题，比如算卡方、选正确的盒图。</li>
<li>小题里有概念题，比如写出三种集成学习算法。</li>
</ul>
</li>
<li>不挂人但是也不保B+，作业/PJ/期末考三部分占比未知</li>
</ol>
<h2 id="第一章-引论"><a href="#第一章-引论" class="headerlink" title="第一章 引论"></a>第一章 引论</h2><p>数据挖掘/KDD：从大量数据中挖掘有趣模式和知识的过程，通常包括数据清理、数据集成、数据选择、数据变换、模式发现、模式评估、知识表示。</p>
<h3 id="挖掘的对象"><a href="#挖掘的对象" class="headerlink" title="挖掘的对象"></a>挖掘的对象</h3><ol>
<li>关系数据库：表的汇集，有实体-联系（<strong>ER</strong>）等数据模型</li>
<li>数据仓库：从多个数据源收集的信息存储库，存放在一致的模式下，通常驻留在单个站点上。围绕主题组织，从历史的角度提供信息，通常是汇总的。用<strong>数据立方体</strong>建模。</li>
<li>事务数据：挖掘频繁项集</li>
</ol>
<h3 id="数据挖掘功能"><a href="#数据挖掘功能" class="headerlink" title="数据挖掘功能"></a>数据挖掘功能</h3><ol>
<li>类/概念描述：特征化与区分</li>
<li>挖掘频繁模式、关联和相关性</li>
<li>用于预测分析的分类与回归</li>
<li>聚类分析</li>
<li>离群点分析</li>
</ol>
<h2 id="第二章-认识数据"><a href="#第二章-认识数据" class="headerlink" title="第二章 认识数据"></a>第二章 认识数据</h2><h3 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h3><ol>
<li>数据对象用属性描述；属性表示数据对象的一个特征，同义词有属性（数据挖掘、数据库）、特征（机器学习）、变量（统计学）、维（数据仓库）。</li>
<li>标称属性：意味着“与名称相关”，值是一些符号或事物的名称，是分类的、枚举的、不定量、无序的。只有众数，没有其他数学运算（eg：颜色、编号、职业）。</li>
<li>二元/布尔属性：01的标称属性。若两种状态有同等价值且权重相同，称为对称的（eg：性别）；否则称为非对称的（eg：病毒阳性），一般将重要结果用1编码。</li>
<li>序数属性：可能的值之间具有意义的序或秩评定，但是相继值之间的差是未知的（eg：饮料大小杯、成绩等级、职位）。记录不能客观度量的主观质量评估，或通过把数值属性离散化得到。有众数和中位数，没有平均值。</li>
<li>数值属性：定量的可度量的量。区间标度属性用相等的单位尺度度量，可以做差，但是由于没有真正的零不能做商（eg：华氏温度、日期）；比率标度属性是具有固定零点的数值属性，可以做差和商（eg：开式温标、文档字数、速度）。数值属性都可以求众数、中位数、平均值。</li>
<li>总结：无序的只有众数、有序的可以求中位数、数值的可以做差和平均值、有零点的可以做商。</li>
<li>离散属性具有有限或无限可数个值（eg：头发颜色、顾客编号、邮政编码）；不离散的属性是连续属性（可与数值属性互换使用），一般用浮点变量表示。</li>
</ol>
<h3 id="数据的基本统计描述"><a href="#数据的基本统计描述" class="headerlink" title="数据的基本统计描述"></a>数据的基本统计描述</h3><ol>
<li>中心趋势度量<ul>
<li>均值/mean：算术均值/加权均值（对极端值很敏感）、截尾均值（丢弃高低极端值之后的均值）</li>
<li>中位数/median（对倾斜、非对称数据描述更好）：数据个数为偶数时，中位数不唯一，取中间两个值和它们之间的任意值；对于数值属性，约定取中间两个值的平均值。中位数的近似值。</li>
<li>众数/mode：根据众数个数将数据集合分为单峰的、双峰的、三峰的、多峰的（两个或更多个峰），N峰也称为N模。每个数据值只出现一次，则没有众数。</li>
<li>对于适度倾斜的单峰数值数据，有经验关系：$mean-mode \approx 3(mean-median)$</li>
<li>中列数/midrange：数据集最大和最小值的平均值。</li>
<li>完全对称的单峰频率曲线中，均值、中位数、众数都是相同的中心值。</li>
<li>正倾斜：众数小于中位数。反之则为负倾斜。</li>
</ul>
</li>
<li>数据散布度量<ul>
<li>极差/range：最大值与最小值之差</li>
<li>分位数/quantile：把数据划分成基本上大小相等的连贯集合，有$q-1$个q-分位数，第$k$个q-分位数是值$x$，小于$x$的数据值最多为$k/q$，大于$x$的数据值最多为$(q-k)/q$。2-分位数是中位数，四分位数依次为$Q_1$、$Q_2$、$Q_3$，又常用百分位数。</li>
<li>四分位数极差：$IQR=Q_3-Q_1$，给出被数据的中间一半覆盖的范围。</li>
<li>五数概括：最小观测值、$Q_1$、中位数、$Q_3$、<strong>最大观测值</strong>。</li>
<li>盒图：端点在四分位数上，长度是IQR，中位数用盒内的线标记，胡须延伸到最大最小观测值。若最大最小观测值距四分位数超过1.5IQR，胡须在距四分位数<strong>1.5IQR内最极端的观测值处</strong>终止，剩下的情况个别绘出。</li>
<li>方差：到均值距离的平方和的均值，或$(\frac{1}{N}\sum_{i=1}^{n}x_{i}^2)^2-\bar{x}^2$。标准差：方差的平方根，度量关于均值的发散。一个观测一般不会远离均值超过标准差的数倍，最少$(1-\frac{1}{k^2})*100%$的观测值离均值不超过k个标准差。</li>
</ul>
</li>
<li>基本统计描述的图形显示<ul>
<li>分位数图（观察单变量数据分布）：横轴为f值(i-0.5)/N，纵轴为观测值。</li>
<li>分位数-分位数图（观察两个分布之间是否有漂移）：横轴为一个观测值，纵轴为另一个观测值，每个点在两个数据集离对应的分位数相同。若两个观测集数据个数不同，以小的为准，需要在大的观测集里插值。</li>
<li>直方图：标称属性的直方图常被称为条形图。数值属性的直方图横轴为不相交的连续子域（桶/箱），通常是等宽的，纵轴为子域内数据的计数。</li>
<li>散点图（确定两个数值变量之间是否存在联系）：每个值对视为一个代数坐标对，作为一个点画在平面上。左下-右上暗示正相关，左上-右下暗示负相关。</li>
</ul>
</li>
</ol>
<h3 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h3><ol>
<li>基于像素的可视化技术：对每一维创建一个窗口。线性填充、空间填充曲线，圆弓分割技术。</li>
<li>几何投影可视化技术：散点图矩阵（随着维数增加变得不太有效）、平行坐标（视觉上的簇和重叠导致不能有效地显示具有很多记录的数据集）</li>
<li>基于图符的可视化技术：切尔诺夫脸（容易被用户消化，在表示多重联系的能力方面存在局限性，最多18维，眼睛大小和眉毛的歪斜是重要的）、非对称的切尔诺夫脸（达到36维）、人物线条画（两个维映射到显示轴，其他维映射到人物线条画，数据关于两个显示维相对稠密则结果显示纹理模式）。</li>
<li>层次可视化技术：世界中的世界（将部分维固定为选定的值，以这个值为原点绘制内世界三维图，在外世界三维图中改变原点位置观察内世界变化）、树图</li>
<li>可视化复杂对象和关系：标签云（用大小表示次数）、图</li>
</ol>
<h3 id="度量数据的差异性和相似性"><a href="#度量数据的差异性和相似性" class="headerlink" title="度量数据的差异性和相似性"></a>度量数据的差异性和相似性</h3><ol>
<li><p>数据矩阵/二模矩阵：对象-属性结构，n*p。每行对应一个对象，又称数据样本/特征向量。</p>
</li>
<li><p>相异性矩阵/单模矩阵：对象-对象结构，n*n，存放对象两两之间的邻近度，对称矩阵。对于标称数据，$sim(i,j)=1-d(i,j)$</p>
</li>
<li><p>标称属性的邻近性度量：$d(i,j)=\frac{p-m}{p}$，m可加权</p>
</li>
<li><p>二元属性的邻近性度量</p>
<ul>
<li>对称的二元相异性$d(i,j)=\frac{r+s}{q+r+s+t}$</li>
<li>非对称的二元相异性$d(i,j)=\frac{r+s}{q+r+s}$</li>
<li>非对称的二元相似性$sim(i,j)=\frac{q}{q+r+s}$，称为Jaccard系数。</li>
</ul>
</li>
<li><p>数值属性的相异性</p>
<ul>
<li>先对数据规范化，如变换到$[-1,1]$或$[0,1]$</li>
<li>欧几里得距离，加权的欧几里得距离</li>
<li>曼哈顿距离</li>
<li>度量：满足非负性、同一性、对称性、三角不等式</li>
<li>闵可夫斯基距离/$L_p$范数：各维距离的p次方之和，开p次方，p是不小于1的实数。$L_1$范数为曼哈顿距离，$L_2$范数为欧几里得距离。</li>
<li>上确界距离/$L_{max}$/$L_{∞}$范数/一致范数/切比雪夫距离：各维距离的最大值</li>
</ul>
</li>
<li><p>序数属性的邻近性度量：对于第$i$个对象，用对应排位$r_{if}$取代序数属性组$x_{if}$，将每个属性的值域映射到$[0,1]$，$z_{if}=\frac{r_{if}-1}{M_f-1}$，再对$z$使用数值属性的距离度量计算相异性</p>
</li>
<li><p>混合类型属性的相异性</p>
<ul>
<li>计算两者均不缺失的所有属性相异性并取平均数</li>
<li>数值属性$d_{ij}^{(f)}=\frac{|x_{if}-x_{jf}|}{max_hx_{hf}-min_hx_{hf}}$</li>
<li>序数属性计算$z$后按数值属性处理</li>
<li>标称属性$d$即为是否相等</li>
</ul>
</li>
<li><p>余弦相似性</p>
<ul>
<li>处理很长的、稀疏的向量，数据往往高度非对称（eg：信息检索、生物学分类）</li>
<li>$sim(x,y)=\frac{x*y}{||x||||y||}$，分母为两个向量欧几里得范数（即长度）之积</li>
<li>0代表两个向量正交，余弦值越小向量之间的匹配越大</li>
<li>不遵守度量测度性质，被称为非度量测度</li>
<li>二值属性的余弦相似性可以用共享特征或属性解释，分子是共同具有的属性数，分母是两个向量具有的属性数的几何均值，sim成为公共属性相对拥有的一种度量，$sim(i,j)=\frac{x<em>y}{x</em>x+y<em>y-x</em>y}$，称为Tanimoto系数或Tanimoto距离</li>
</ul>
</li>
</ol>
<h2 id="第三章-数据预处理"><a href="#第三章-数据预处理" class="headerlink" title="第三章 数据预处理"></a>第三章 数据预处理</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><ol>
<li><p>数据质量的三个要素：准确性、完整性、一致性</p>
</li>
<li><p>影响数据质量的要素：时效性、可解释性、可信性</p>
</li>
<li><p>主要步骤：数据清理、数据集成、数据归约、数据变换</p>
</li>
</ol>
<h3 id="数据清理"><a href="#数据清理" class="headerlink" title="数据清理"></a>数据清理</h3><ol>
<li>缺失值</li>
<li>噪声数据：分箱、回归、离群点分析</li>
<li>偏差检测，数据变换两步的迭代过程</li>
<li>数据清洗工具，数据审计工具，数据迁移工具，ETL工具</li>
</ol>
<h3 id="数据集成"><a href="#数据集成" class="headerlink" title="数据集成"></a>数据集成</h3><ol>
<li>实体识别问题：使用元数据</li>
<li>冗余和相关分析<ul>
<li>标称数据的卡方检验：相依表中$o_{ij}$为联合事件观测频度，$e_{ij}$为期望频度，可用$e_{ij}=\frac{count(A=a_i)<em>count(B=b_j)}{n}$计算，卡方=$\sum_{i=1}^c\sum_{j=1}^r\frac{(o_{ij}-e_{ij})^2}{e_{ij}}$，对卡方贡献越大的单元实际计数与期望计数越不符。卡方检验假设A和B是独立的，具有自由度$(r-1)</em>(c-1)$，自由度和置信水平决定拒绝假设的值</li>
<li>数值数据的相关系数/Pearson积矩系数：$r_{A,B}=\frac{\sum_{i=1}^n(a_i-\bar A)(b_i-\bar B)}{n\sigma_A\sigma_B}=\frac{\sum_{i=1}^n(a_ib_i)-n\bar A\bar B}{n\sigma_A\sigma_B}$；r越接近1，正相关越强；越接近-1，负相关越强；r为0，A和B独立。相关性不蕴涵因果关系</li>
<li>数值数据的协方差：$Cov(A,B)=E((A-\bar A)(B-\bar B))=\frac{\sum_{i=1}^n(a_i-\bar A)(b_i-\bar B)}{n}=E(A*B)-\bar A\bar B=r_{A,B}\sigma_A\sigma_B$；协方差为正表示正相关，协方差为负表示负相关；A和B独立时协方差一定为0，但A和B不独立协方差也可能为0，只有当数据满足多元正态分布等限制条件时协方差为0才充分说明数据独立。方差是属性和自身的协方差</li>
</ul>
</li>
<li>元组重复</li>
<li>数据值冲突的检测与处理</li>
</ol>
<h3 id="数据归约"><a href="#数据归约" class="headerlink" title="数据归约"></a>数据归约</h3><ol>
<li>维归约：小波变换、主成分分析、属性子集选择、属性创建</li>
<li>数量归约：参数方法（回归、对数-线性模型）、非参数方法（直方图、聚类、抽样、数据立方体聚集）</li>
<li>数据压缩：有损的、无损的</li>
<li>离散小波变换（DWT）<ul>
<li>将数据向量X变换成不同的数值小波系数向量X’，变换后数据可以截短，仅存放一部分最强的小波系数，消除噪声</li>
<li>有损压缩，比DFT更准确，空间局部性好，对稀疏或倾斜数据和具有有序属性的数据效果好</li>
<li>层次金字塔算法：每次迭代数据减半，先后使用光滑和加权差分函数，得到两个长度为L/2的数据集，分别代表光滑后的版本或低频版本和它的高频内容</li>
<li>有若干族DWT，小波名后的数是小波的消失瞬间</li>
<li>将矩阵乘法用于输入数据，所用的矩阵必须是标准正交的</li>
<li>处理多维数据，首先将变换用于第一个维，然后第二个，复杂度关于立方体中单元的个数是线性的</li>
</ul>
</li>
<li>主成分分析/PCA<ul>
<li>搜索k个最能代表数据的n维正交向量，k&lt;=n</li>
<li>对输入数据规范化，计算k个标准正交向量（主成分），对主成分按重要性或强度降序排列，主成分本质上充当新坐标系，通过去掉较弱的成分（方差较小的那些）来规约数据</li>
<li>可用于有序和无序的属性，可以处理稀疏和倾斜数据，可以用做多元回归和聚类分析的输入</li>
<li>多于二维的多维数据可以通过将问题归约为二维问题来处理</li>
<li>小波变换更适合高维数据，PCA能够更好处理稀疏数据</li>
</ul>
</li>
<li>属性子集选择<ul>
<li>删除不相关或冗余属性，目标是找出最小属性集，使数据类的概率分布尽可能接近原分布</li>
<li>压缩搜索空间的启发式算法：贪心，取局部最优解</li>
<li>确定”最好/差的“属性：统计显著性检验/信息增益度量</li>
<li>具体技术：逐步向前选择、逐步向后删除、逐步向前选择和逐步向后删除的组合、决策树归纳</li>
</ul>
</li>
<li>回归和对数线性模型<ul>
<li>参数化数据归约</li>
<li>线性回归（最小二乘法求解回归系数）、多元回归</li>
<li>对数线性模型：近似离散的多维概率分布，基于维组合的一个较小子集估计多维空间中每个点的概率</li>
<li>都可以用于稀疏数据。回归对倾斜数据可望更好，对数线性模型对高维数据伸缩性好，可达10维</li>
</ul>
</li>
<li>直方图<ul>
<li>等宽直方图，等频/等深直方图</li>
<li>对于近似稀疏和稠密数据，以及高倾斜和均匀的数据，都是非常有效的</li>
<li>多维直方图可以表现属性间的依赖，能有效近似多达5个属性的数据</li>
<li>对于存放具有高频率的离群点，单值桶是有用的</li>
</ul>
</li>
<li>聚类<ul>
<li>直径：簇中两个对象的最大距离</li>
<li>形心距离：簇中每个对象到簇形心（平均对象/空间中的平均点）的平均距离</li>
<li>数据归约中用簇代表替换实际数据，对于能够组织成不同的簇的数据较为有用</li>
</ul>
</li>
<li>抽样<ul>
<li>s个样本的无放回简单随机抽样（SRSWOR）</li>
<li>s个样本的有放回简单随机抽样（SRSWR）</li>
<li>簇抽样：每次抽取一个簇</li>
<li>分层抽样：数据倾斜时可以帮助确保样本的代表性</li>
<li>得到样本的花费正比例于样本集的大小s，而不是数据集的大小N，因此复杂度亚线性于数据大小，仅根据数据的维数n线性增加</li>
<li>常用来估计聚集查询的回答，通过简单的增加样本大小可以进一步求精</li>
</ul>
</li>
<li>数据立方体聚集<ul>
<li>每个属性都可能存在概念分层，允许在多个抽象层进行数据分析</li>
<li>数据立方体提供对与计算的汇总数据进行快速访问，适合联机数据分析和数据挖掘</li>
<li>在最低抽象层创建的立方体称为基本方体，应当对应于感兴趣的个体实体</li>
<li>最高抽象层的立方体称为顶点方体</li>
<li>不同层创建的数据立方体称为方体，数据立方体可以看作方体的格</li>
<li>回答询问时使用与给定任务相关的最小可用方体</li>
</ul>
</li>
</ol>
<h3 id="数据变换与数据离散化"><a href="#数据变换与数据离散化" class="headerlink" title="数据变换与数据离散化"></a>数据变换与数据离散化</h3><ol>
<li>光滑：去掉数据中的噪声，包括分箱、回归和聚类</li>
<li>属性构造/特征构造：由给定属性创造新属性</li>
<li>聚集：一般用来维多个抽象层的数据分析构造数据立方体</li>
<li>规范化/标准化：把属性数据按比例缩放到特定小区间<ul>
<li>最小-最大规范化：$v_i’=\frac{v_i-min_A}{max_A-min_A}(max_A’-min_A’)+min_A’$，保持原始数据之间的联系，但新输入落在原始数据值域外可能越界</li>
<li>z分数规范化/z-score规范化/零均值规范化：$v_i’=\frac{v_i-\bar A}{\sigma_A}$，实际最大最小值未知或离群点左右了最小-最大规范化时是有用的。标准差可用均值绝对偏差$s_A$替换，对离群点更鲁棒</li>
<li>小数定标规范化：通过移动属性A的小数点位置进行规范化，$v_i’=\frac{v_i}{10^j}$，j是使得$max(|v_i’|)&lt;1$的最小整数</li>
<li>有必要保留规范化参数，以便将来的数据可以用一致的方式规范化</li>
</ul>
</li>
<li>离散化：将数值属性原始值用区间标签或概念标签替换<ul>
<li>监督的离散化和非监督的离散化：是否使用类信息</li>
<li>自顶向下离散化/分裂，自底向上离散化/合并</li>
<li>分箱离散化：等宽/等频分箱，用箱均值/中位数替换箱中的每个值，是非监督的离散化技术，对用户指定的箱个数和离群点很敏感</li>
<li>直方图离散化：非监督，可以递归地用于每个分区，自动产生多级概念分层，用预设概念层数或最小区间长度控制递归过程</li>
<li>聚类</li>
<li>决策树：监督的离散化，选择最小化熵的值作为划分点</li>
<li>相关分析离散化：监督的离散化，ChiMerge，自底向上递归找出具有最小卡方值的相邻区间并合并（对于精确的离散化，相对类频率在一个区间内应当完全一致）</li>
</ul>
</li>
<li>由标称数据产生概念分层：利用模式和属性值计数信息</li>
</ol>
<h2 id="第四章-数据仓库与联机分析处理"><a href="#第四章-数据仓库与联机分析处理" class="headerlink" title="第四章 数据仓库与联机分析处理"></a>第四章 数据仓库与联机分析处理</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><ol>
<li>主要特征：面向主题的、集成的、时变的、非易失的</li>
<li>使用更新驱动而非查询驱动方法</li>
<li>操作数据库与数据仓库分离，OLTP和OLAP分离</li>
<li>OLAP系统面向市场（而非面向顾客），管理大量历史数据（而非当前数据），采用星形或雪花模型和面向主题的数据库设计（而非ER模型和面向应用的数据库设计），常常跨越数据库模式的多个版本，存放在多个存储介质上，大部分是只读操作</li>
<li>三层体系结构：底层是仓库数据库服务器，中间层是OLAP服务器，顶层是前端客户层</li>
<li>数据仓库模型：企业仓库，数据集市和虚拟仓库</li>
<li>数据提取、变换和装入</li>
<li>元数据库：关于数据的数据，应当持久存放和管理（即存放在磁盘上）</li>
</ol>
<h3 id="数据立方体与OLAP"><a href="#数据立方体与OLAP" class="headerlink" title="数据立方体与OLAP"></a>数据立方体与OLAP</h3><ol>
<li>数据立方体由维和事实定义，是n维的</li>
<li>数据立方体称作方体。给定维的集合，可以对给定诸维的每个子集产生一个方体，结果形成方体的格，称作数据立方体。存放最低层汇总的方体称作基本方体，最高层汇总的方体称作顶点方体。</li>
<li>多维数据模型<ul>
<li>星形模式：一个事实表+一组维表</li>
<li>雪花模式：在星形模式的基础上将某些维表规范化</li>
<li>星系模式/事实星座：多个事实表共享维表</li>
<li>数据仓库通常使用事实星座模式，数据集市流行采用星形或雪花模式</li>
</ul>
</li>
<li>概念分层<ul>
<li>模式分层：形成数据库模式中属性的全序或偏序的概念分层</li>
<li>集合分组分层：将给定维或属性的值离散化或分组</li>
</ul>
</li>
<li>度量的分类和计算<ul>
<li>数据立方体度量是一个数值函数，可以对数据立方体空间的每个点求值，通过对给定点的各维-值对聚集数据，计算该点的度量值</li>
<li>度量分类：分布的（可以划分计算，eg：sum、count、min）、代数的（可以由多个划分计算的结果得到，eg：avg、min_N)、整体的（描述子聚集所需的存储没有常数界，eg：median、mode、rank）</li>
</ul>
</li>
<li>典型的OLAP操作<ul>
<li>上卷（roll-up）/上钻（drill-up）：通过沿一个维的概念分层向上攀升，泛化</li>
<li>下钻（drill-down）：通过沿一个维的概念分层向下或引入附加的维，特殊化</li>
<li>切片（slice）：在一个维进行选择</li>
<li>切块（dice）：在两个或多个维进行选择</li>
<li>转轴（pivot）/旋转（rotate）：转动数据视角</li>
<li>钻过（drill-across）：执行涉及多个事实表的查询</li>
<li>钻透（drill-through）：使用关系SQL机制钻透到后端关系表</li>
</ul>
</li>
<li>星网模型：由从中心点发出的射线组成，其中每一条射线代表一个维的概念分层，概念分层上的每个”抽象级“称为一个足迹，代表 OLAP操作可用的粒度</li>
</ol>
<h3 id="数据仓库的设计与使用"><a href="#数据仓库的设计与使用" class="headerlink" title="数据仓库的设计与使用"></a>数据仓库的设计与使用</h3><ol>
<li>商务分析框架：自顶向下视图、数据源视图、数据仓库视图、商务查询视图</li>
<li>开发方法：瀑布式方法、螺旋式方法</li>
<li>数据仓库应用：信息处理、分析处理、数据挖掘</li>
<li>多维数据挖掘/探索式多维数据挖掘/联机分析挖掘/OLAM</li>
</ol>
<h3 id="数据仓库的实现"><a href="#数据仓库的实现" class="headerlink" title="数据仓库的实现"></a>数据仓库的实现</h3><ol>
<li>compute cube：在操作指定的维的所有子集上计算聚集</li>
<li>维灾难：n维方体总数=$\prod_{i=1}^n(L_i+1)$</li>
<li>不物化、完全物化、部分物化</li>
<li>冰山立方体：只存放聚集值大于某个最小支持度阈值的立方体单元</li>
<li>外壳立方体</li>
<li>位图索引，连接索引，复合连接索引，位图连接索引</li>
<li>关系OLAP（ROLAP）服务器：伸缩性好，映射到关系操作；多维OLAP（MOLAP）服务器：适用稠密子立方体，映射到数组结构；混合OLAP（HOLAP）服务器；特殊的SQL服务器</li>
</ol>
<h3 id="数据泛化：面向属性的归纳"><a href="#数据泛化：面向属性的归纳" class="headerlink" title="数据泛化：面向属性的归纳"></a>数据泛化：面向属性的归纳</h3><ol>
<li>属性删除：某个属性有大量不同值但没有泛化操作符，或较高层概念用其他属性表示</li>
<li>属性泛化：某个属性有大量不同值且存在泛化操作符</li>
<li>属性泛化控制：属性泛化阈值控制、广义关系阈值控制</li>
<li>面向属性归纳：关系查询-收集初始关系上的统计量-导出主关系P</li>
<li>类比较：数据收集-维相关分析-同步泛化-导出比较的表示</li>
</ol>
<h2 id="第五章-数据立方体技术"><a href="#第五章-数据立方体技术" class="headerlink" title="第五章 数据立方体技术"></a>第五章 数据立方体技术</h2><h3 id="基本概念-1"><a href="#基本概念-1" class="headerlink" title="基本概念"></a>基本概念</h3><ol>
<li>基本方体的单元是基本单元，非基本方体的单元是聚集单元</li>
<li>祖先和后代单元，父母和子女单元</li>
<li>闭覆盖：一个单元c是闭单元，如果不存在后代d与c有相同的度量值；闭立方体是只由闭单元组成的数据立方体</li>
<li>立方体外壳，外壳片段</li>
<li>优化技术：散列、排序、分组、同时聚集和缓存中间结果、由最小的子女聚集、先验剪枝</li>
</ol>
<h3 id="数据立方体计算方法"><a href="#数据立方体计算方法" class="headerlink" title="数据立方体计算方法"></a>数据立方体计算方法</h3><ol>
<li>多路数组聚集（MultiWay）：扫描顺序决定保持二维平面在块内存中的最小内存需求量；适合维的基数乘积适中且数据不是太稀疏的情况，但是不能先验剪枝</li>
<li>BUC：自顶向下，容易受维的次序和倾斜数据的影响，理想情况下应先处理最有区分能力的维，应当以维的基数减序处理</li>
<li>Star-Cubing<ul>
<li>共享维剪枝</li>
<li>方体树，星树</li>
<li>计算完全立方体，稠密时接近MultiWay，比BUC快；稀疏时比MultiWay快很多，大部分情况下比BUC快</li>
<li>计算冰山立方体，比BUC快</li>
</ul>
</li>
<li>计算外壳片段：倒排索引，Frag-Shells</li>
<li>点查询，子立方体查询</li>
</ol>
<h3 id="高级查询"><a href="#高级查询" class="headerlink" title="高级查询"></a>高级查询</h3><ol>
<li>抽样立方体<ul>
<li>置信区间$\bar x ±t_c\sigma_{\bar x}$，$t_c$与置信水平相关，$\sigma_{\bar x}=\frac{s}{\sqrt l}$是均值的估计标准误差，自由度为$l-1$，$l$为样本数</li>
<li>提升小样本置信度：方体内查询扩展、方体间查询扩展</li>
</ul>
</li>
<li>排序立方体</li>
</ol>
<h3 id="多维数据分析"><a href="#多维数据分析" class="headerlink" title="多维数据分析"></a>多维数据分析</h3><ol>
<li>预测立方体</li>
<li>多特征立方体：多粒度上多个依赖的聚集的复杂查询</li>
<li>基于异常的、发现驱动的立方体空间探查<ul>
<li>SelfExp，InExp，PathExp</li>
<li>给定单元的值和它的期望值之间的差称为残差，残差越大越异常，要对残差定标</li>
</ul>
</li>
</ol>
<h2 id="第六章-挖掘频繁模式、关联和相关性：基本概念和方法"><a href="#第六章-挖掘频繁模式、关联和相关性：基本概念和方法" class="headerlink" title="第六章 挖掘频繁模式、关联和相关性：基本概念和方法"></a>第六章 挖掘频繁模式、关联和相关性：基本概念和方法</h2><h3 id="基本概念-2"><a href="#基本概念-2" class="headerlink" title="基本概念"></a>基本概念</h3><ol>
<li>频繁模式：频繁出现在数据集中的模式，如频繁项集、频繁序列模式</li>
<li>有趣的关联规则：满足最小支持度阈值和最小置信度阈值</li>
<li>支持度support(A-&gt;B)=P(A$\cup$B)</li>
<li>置信度confidence(A-&gt;B)=P(B|A)=support(A$\cup$B)/support(A)</li>
<li>闭频繁项集：不存在频繁项集X的真超集Y，使得Y与X在D中支持度相同</li>
<li>极大频繁项集：不存在频繁项集X的超集Y，使得Y在D中是频繁的</li>
</ol>
<h3 id="频繁项集挖掘方法"><a href="#频繁项集挖掘方法" class="headerlink" title="频繁项集挖掘方法"></a>频繁项集挖掘方法</h3><ol>
<li><p>Apriori（先验）算法</p>
<ul>
<li>先验性质，属于反单调性</li>
<li>连接步，剪枝步</li>
<li>由频繁项集枚举子集，产生关联规则</li>
<li>优化方法：散列技术、事务压缩、划分、抽样、动态项集计数</li>
</ul>
</li>
<li><p>FP-growth（频繁模式增长）算法</p>
<ul>
<li>导出频繁项的集合，构造FP树</li>
<li>从表后端的后缀模式开始构造条件模式基</li>
</ul>
</li>
<li><p>使用垂直数据格式挖掘频繁项集</p>
<ul>
<li><p>不需要扫描数据库来确定k+1项集的支持度</p>
</li>
<li><p>差集技术：数据集稠密和包含长模式时，可以显著降低总开销</p>
</li>
</ul>
</li>
<li><p>挖掘闭模式和极大模式</p>
<ul>
<li>项合并</li>
<li>子项集剪枝</li>
<li>项跳过</li>
</ul>
</li>
</ol>
<h3 id="模式评估方法"><a href="#模式评估方法" class="headerlink" title="模式评估方法"></a>模式评估方法</h3><ol>
<li>提升度：$lift(A,B)=\frac{P(A\cup B)}{P(A)P(B)}=\frac{P(B|A)}{P(B)}=\frac{conf(A-&gt;B)}{sup(B)}$，小于1为负相关，大于1为正相关，等于1为独立</li>
<li>全置信度：min{P(A|B),P(B|A)}</li>
<li>最大置信度：max{P(A|B),P(B|A)}</li>
<li>Kulczynski（Kulc）度量：0.5(P(A|B)+P(B|A))</li>
<li>余弦度量：$\sqrt{P(A|B)+P(B|A)}$</li>
<li>不平衡比：$IR(A,B)=\frac{|sup(A)-sup(B)|}{sup(A)+sup(B)-sup(A\cup B)}$</li>
<li>全置信度、最大置信度、Kulc和余弦是零不变的，推荐Kulc和IR配合使用</li>
</ol>
<h2 id="第七章-高级模式挖掘"><a href="#第七章-高级模式挖掘" class="headerlink" title="第七章 高级模式挖掘"></a>第七章 高级模式挖掘</h2><h3 id="多层、多维空间中的模式挖掘"><a href="#多层、多维空间中的模式挖掘" class="headerlink" title="多层、多维空间中的模式挖掘"></a>多层、多维空间中的模式挖掘</h3><ol>
<li>挖掘多层关联规则</li>
<li>检查多层关联规则的冗余性：根据规则的祖先，它的支持度和置信度都接近于期望值</li>
<li>挖掘多维关联规则</li>
<li>挖掘量化关联规则</li>
<li>挖掘稀有模式和负模式<ul>
<li>稀有模式支持度远低于用户指定的最小支持度阈值</li>
<li>负相关：X和Y都是频繁的，但很少一起出现</li>
<li>直接用sup定义的强负相关并不是零不变的</li>
<li>零不变的强负相关定义：Kulc度量小于负模式阈值</li>
</ul>
</li>
</ol>
<h3 id="基于约束的频繁模式挖掘"><a href="#基于约束的频繁模式挖掘" class="headerlink" title="基于约束的频繁模式挖掘"></a>基于约束的频繁模式挖掘</h3><ol>
<li>用模式剪枝约束对模式空间剪枝<ul>
<li>反单调的</li>
<li>单调的</li>
<li>简洁的</li>
<li>可转变的</li>
<li>不可转变的</li>
</ul>
</li>
<li>用数据剪枝约束对数据空间剪枝<ul>
<li>数据简洁</li>
<li>数据反单调</li>
</ul>
</li>
</ol>
<h3 id="挖掘高维数据和巨型模式"><a href="#挖掘高维数据和巨型模式" class="headerlink" title="挖掘高维数据和巨型模式"></a>挖掘高维数据和巨型模式</h3><ol>
<li>通过模式融合挖掘巨型模式<ul>
<li>核模式（核后代）、核比率</li>
<li>鲁棒</li>
<li>模式距离</li>
<li>池初始化-迭代的模式融合</li>
</ul>
</li>
</ol>
<h3 id="挖掘压缩或近似模式"><a href="#挖掘压缩或近似模式" class="headerlink" title="挖掘压缩或近似模式"></a>挖掘压缩或近似模式</h3><ol>
<li>通过模式聚类挖掘压缩模式：模式距离</li>
<li>提取感知冗余的top-k模式<ul>
<li>显著性度量S</li>
<li>S(p,q)联合显著性，S(p|q)=S(p,q)-S(q)相对显著性</li>
<li>冗余性R(p,q)=S(p)+S(q)-S(p,q)，所以S(p|q)=S(p)-R(p,q)</li>
<li>可以用模式间的距离近似冗余度</li>
</ul>
</li>
</ol>
<h3 id="模式探索与应用"><a href="#模式探索与应用" class="headerlink" title="模式探索与应用"></a>模式探索与应用</h3><ol>
<li>频繁模式的语义注解：互信息</li>
<li>模式挖掘的应用</li>
</ol>
<h2 id="第八章-分类：基本概念"><a href="#第八章-分类：基本概念" class="headerlink" title="第八章 分类：基本概念"></a>第八章 分类：基本概念</h2><h3 id="决策树归纳"><a href="#决策树归纳" class="headerlink" title="决策树归纳"></a>决策树归纳</h3><ol>
<li>属性选择度量<ul>
<li>信息增益：信息需求$Info(D)=-\sum_{i=1}^mp_ilog_2(p_i)$，$p_i$用$|C_{i,D}|/|D|$估计；$Info_A(D)=\sum_{j=1}^v\frac{|D_j|}{D}*Info(D_j)$，$Info_A(D)$越小，分区纯度越高；信息增益$Gain(A)=Info(D)-Info_A(D)$</li>
<li>增益率：分裂信息$SplitInfo_A(D)=-\sum_{j=1}^v\frac{|D_j|}{D}*log_2(\frac{|D_j|}{|D|})$，增益率$GRianRate(A)=\frac{Gain(A)}{SplitInfo_A(D)}$</li>
<li>基尼系数：$Gini(D)=1-\sum_{i=1}^mp_i^2$度量数据分区或训练元组集D的不纯度；考虑二元划分裂时，计算每个结果分区不纯度加权和；对连续值属性，最大化不纯度降低</li>
<li>基于最小描述长度原理的属性</li>
</ul>
</li>
<li>树剪枝：先剪枝，后剪枝（代价复杂度剪枝算法，应用剪枝集）</li>
<li>可伸缩性与决策树归纳：雨林（在每个结点维护每个属性的AVC-集），树构造的自助乐观算法（BOAT）</li>
<li>决策树归纳的可视化挖掘：基于感知的分类（PBC）</li>
</ol>
<h3 id="贝叶斯分类方法"><a href="#贝叶斯分类方法" class="headerlink" title="贝叶斯分类方法"></a>贝叶斯分类方法</h3><ol>
<li>贝叶斯定理<ul>
<li>后验概率P(H|X)</li>
<li>P(H|X)=P(X|H)P(H)/P(X)</li>
</ul>
</li>
<li>朴素贝叶斯分类<ul>
<li>预测X属于在X条件下有最高后验概率的类</li>
<li>等价于最大化P(X|Ci)P(Ci)</li>
<li>若P(Ci)未知则假定等概率，否则用Ci/D估计</li>
<li>类条件独立的朴素假定：P(X|Ci)=P(x1|Ci)P(x2|Ci)……P(xn|Ci)</li>
<li>连续值属性的概率用高斯分布定义</li>
<li>拉普拉斯校准/拉普拉斯估计法</li>
</ul>
</li>
</ol>
<h3 id="基于规则的分类"><a href="#基于规则的分类" class="headerlink" title="基于规则的分类"></a>基于规则的分类</h3><ol>
<li>规则：规则前件/前提IF，规则结论THEN</li>
<li>覆盖率$coverage(R)=n_{covers}/|D|$</li>
<li>准确率$accuracy(R)=n_{correct}/n_{covers}$</li>
<li>规模序：优先最苛刻的规则，即前件规模最大、激活具有最多属性测试的被触发的规则</li>
<li>规则序：预定规则的优先次序</li>
<li>由决策树提取规则：规则是互斥的和穷举的</li>
<li>使用顺序覆盖算法的规则归纳<ul>
<li>贪心的深度优先策略</li>
<li>用于规则学习的称为正元组pos，其余称为负元组neg</li>
<li>信息增益$FOIL-Gain=pos’*(log_2\frac{pos’}{pos’+neg’}-log_2\frac{pos}{pos+neg})$；似然率统计量$Likelihood-Ratio=2\sum_{i=1}^mf_ilog(\frac{f_i}{e_i})$，似然率越高正确预测数与随机猜测差越显著</li>
<li>规则剪枝$FOIL-Prune(R)=\frac{pos-neg}{pos+neg}$</li>
</ul>
</li>
</ol>
<h3 id="模型评估与选择"><a href="#模型评估与选择" class="headerlink" title="模型评估与选择"></a>模型评估与选择</h3><ol>
<li>混淆矩阵——真阳性：TP；真阴性：TN；假阳性：FP；假阴性：FN</li>
<li>准确率/总体识别率：$accuracy=\frac{TP+TN}{P+N}$</li>
<li>错误率：1-accuracy</li>
<li>灵敏性/召回率：$sensitivity=\frac{TP}{P}=\frac{TP}{TP+FN}=recall$</li>
<li>特效性：$specificity=\frac{TN}{N}$</li>
<li>精度：$precision=\frac{TP}{TP+FP}$</li>
<li>$F_x$分数：$F_x=\frac{(1+x^2)<em>precision</em>recall}{x^2*precision+recall}$，x为1时称为F度量/F分数</li>
<li>保持方法和随机二次抽样</li>
<li>交叉验证<ul>
<li>k-折交叉验证：初始数据随机划分成k个互不相交的子集D，训练和检验进行k次，每次留下一个D检验</li>
<li>留一：每次只给检验集留出一个样本</li>
<li>分层交叉验证</li>
<li>建议用分层10-折交叉验证估计准确率</li>
</ul>
</li>
<li>自助法：有放回，.632，$Acc(M)=\sum_{i=1}^k(0.632<em>Acc(M_i)_{test-set}+0.368</em>Acc(M_i)train-set)$</li>
<li>统计显著性：t-test，显著水平sig，置信界z=sig/2<ul>
<li>$t=\frac{\bar {err}(M_1)-\bar {err}(M_2)}{\sqrt{var(M_1-M_2)/k}}$，var为模型差的方差，若有两个检验集，方差估计为$\sqrt{var(M_1)/k_1+var(M_2)/k_2}$</li>
</ul>
</li>
<li>成本效益</li>
<li>ROC曲线<ul>
<li>真正例率TPR=TP/P</li>
<li>假正例率TFR=FP/N</li>
<li>概率从高到低排序，真正例TP增加，假正例FP增加</li>
<li>用当前混淆矩阵计算(FPR,TPR)并将点绘在图中</li>
<li>ROC曲线越接近随机猜测，模型准确率越低</li>
</ul>
</li>
</ol>
<h3 id="提高分类准确率的技术"><a href="#提高分类准确率的技术" class="headerlink" title="提高分类准确率的技术"></a>提高分类准确率的技术</h3><ol>
<li>组合分类方法</li>
<li>装袋：有放回抽样，多数表决</li>
<li>提升和AdaBoost：给不正确分类的元组加权，不同分类器的表决权重也取决于错误率</li>
<li>随机森林</li>
<li>提高类不平衡数据的分类准确率：过抽样、欠抽样、阈值移动、组合技术</li>
</ol>
<h2 id="第九章-分类：高级方法"><a href="#第九章-分类：高级方法" class="headerlink" title="第九章 分类：高级方法"></a>第九章 分类：高级方法</h2><h3 id="贝叶斯信念网络"><a href="#贝叶斯信念网络" class="headerlink" title="贝叶斯信念网络"></a>贝叶斯信念网络</h3><ol>
<li>计算梯度</li>
<li>沿梯度方向前进一小步</li>
<li>重新规格化权重</li>
</ol>
<h3 id="用后向传播分类"><a href="#用后向传播分类" class="headerlink" title="用后向传播分类"></a>用后向传播分类</h3><ol>
<li>多层前馈神经网络</li>
<li>后向传播：初始化权重，向前传播输入，向后传播误差</li>
<li>可增强可解释性</li>
</ol>
<h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h3><ol>
<li>对线性和非线性数据进行分类</li>
<li>SVM搜索最大边缘超平面（MMH）</li>
<li>支持向量：最难分类的元组，给出最多支持信息</li>
</ol>
<h3 id="使用频繁模式分类"><a href="#使用频繁模式分类" class="headerlink" title="使用频繁模式分类"></a>使用频繁模式分类</h3><h3 id="惰性学习法（近邻学习）"><a href="#惰性学习法（近邻学习）" class="headerlink" title="惰性学习法（近邻学习）"></a>惰性学习法（近邻学习）</h3><ol>
<li>距离最近的k个中取最多</li>
<li>训练元组趋于无穷，k=1，错误率不超过贝叶斯错误率的2倍；k趋于无穷，错误率趋向于贝叶斯错误率</li>
<li>基于案例的推理</li>
</ol>
<h3 id="其他分类方法"><a href="#其他分类方法" class="headerlink" title="其他分类方法"></a>其他分类方法</h3><ol>
<li>遗传算法</li>
<li>粗糙集算法</li>
<li>模糊集算法</li>
<li>多类分类</li>
<li>半监督分类</li>
<li>主动学习</li>
<li>迁移学习</li>
</ol>
<h2 id="第十章-聚类分析：基本概念和方法"><a href="#第十章-聚类分析：基本概念和方法" class="headerlink" title="第十章 聚类分析：基本概念和方法"></a>第十章 聚类分析：基本概念和方法</h2><ol>
<li>划分方法：k-均值，k-中心点</li>
<li>层次方法</li>
<li>基于密度的方法</li>
<li>基于网格的方法</li>
<li>簇的形心、半径、直径</li>
<li>聚类评估</li>
</ol>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/AcceptedHelper/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/AcceptedHelper/tags/%E5%AD%99%E8%8B%A5%E8%AF%97/">孙若诗</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/AcceptedHelper/2022/01/13/computer_graphics/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">计算机图形学笔记</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/AcceptedHelper/2021/11/17/web_note/">
                        <span class="hidden-mobile">计网笔记</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                
  <script type="text/javascript">
    Fluid.utils.lazyComments('comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'FDU19CS/Comments_utterances');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     FDU <i class="iconfont icon-love"></i> 19CS 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" ></script>
<script  src="/AcceptedHelper/js/debouncer.js" ></script>
<script  src="/AcceptedHelper/js/events.js" ></script>
<script  src="/AcceptedHelper/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/AcceptedHelper/js/img-lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.0/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.0/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>






  <script  src="/AcceptedHelper/js/local-search.js" ></script>
  <script>
    (function () {
      var path = "/AcceptedHelper/local-search.xml";
      $('#local-search-input').on('click', function() {
        searchFunc(path, 'local-search-input', 'local-search-result');
      });
      $('#modalSearch').on('shown.bs.modal', function() {
        $('#local-search-input').focus();
      });
    })()
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-svg.js" ></script>

  











<!-- 主题的启动项 保持在最底部 -->
<script  src="/AcceptedHelper/js/boot.js" ></script>


</body>
</html>
